{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do we have gpu access? True \n",
      " what is torch version? 2.3.0 \n",
      " how many gpus? 1\n",
      "image size:  (64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "# the number of images to process in one go\n",
    "batch_size = 64\n",
    "# the path where our images are\n",
    "source_path = os.path.join(\"/data\")\n",
    "# check that we have access to a GPU, pytorch version, and the number of gpus\n",
    "print('do we have gpu access? {} \\n what is torch version? {} \\n how many gpus? {}'.format(torch.cuda.is_available(), \n",
    "                                                                                           torch.__version__, \n",
    "                                                                                           torch.cuda.device_count()))\n",
    "\n",
    "# this loads the monster data\n",
    "# scales it to be 64x64, converts\n",
    "# it to a torch tensor and then\n",
    "# normalizes the input to be between\n",
    "# -1 and 1, also shuffle the dataset\n",
    "monster_transform = transforms.Compose([\n",
    "         transforms.Resize((64, 64)),\n",
    "         transforms.CenterCrop(64),\n",
    "         transforms.ToTensor(), \n",
    "         transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5)),\n",
    "        ])\n",
    "# this loads the actual files and applies the above transformation\n",
    "monster_dataset = ImageFolder(root=\"/data\", transform=monster_transform)\n",
    "# thes describes how to load that data, whether to shuffle,\n",
    "# how mnay cpus (workers to use), ett. it gets batches of \n",
    "# data so for example grabbing 64 images at once\n",
    "monster_loader = data.DataLoader(dataset=monster_dataset, \n",
    "                              batch_size=batch_size,\n",
    "                              shuffle=True,\n",
    "                              num_workers=1)\n",
    "\n",
    "# check the shape of our pach of images,\n",
    "# this seems right, we have 64 images and\n",
    "# they are sized 64x64x3 \n",
    "for imgs, _ in monster_loader:\n",
    "    # renomalize a single image\n",
    "    single_image = imgs[0]  # first image in batch\n",
    "    single_image = (single_image * 0.5) + 0.5\n",
    "    single_image = single_image.clamp(0, 1)\n",
    "    single_image = single_image.numpy()\n",
    "    # move the dimensions around to get them right\n",
    "    single_image = np.transpose(single_image, (1, 2, 0))\n",
    "    # plot image\n",
    "    print('image size: ', single_image.shape)\n",
    "    plt.imshow(single_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for various parts of the model\n",
    "n_epochs = 200\n",
    "lr = 0.0002\n",
    "label_smooth = 0.9\n",
    "pokemon_models = os.path.join(\"/data\")\n",
    "noise_dim = 100\n",
    "d_filter_depth_in = 3\n",
    "\n",
    "# create our generator network\n",
    "# this network will take in \n",
    "# random noise and output a\n",
    "# monster.\n",
    "class Generator(nn.Module):\n",
    "    # define the model it has 5 transpose\n",
    "    # convolutions and uses relu activations\n",
    "    # it has a TanH activation on the last\n",
    "    # layer\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(noise_dim, \n",
    "                              512, \n",
    "                              kernel_size=4, \n",
    "                              stride=1, \n",
    "                              padding=0,\n",
    "                              bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(512, \n",
    "                              256, \n",
    "                              kernel_size=4, \n",
    "                              stride=2,\n",
    "                              padding=1,\n",
    "                              bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, \n",
    "                              128, \n",
    "                              kernel_size=4, \n",
    "                              stride=2, \n",
    "                              padding=1,\n",
    "                              bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, \n",
    "                              64, \n",
    "                              kernel_size=4, \n",
    "                              stride=2, \n",
    "                              padding=1,\n",
    "                              bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, \n",
    "                               d_filter_depth_in,\n",
    "                               kernel_size=4,\n",
    "                               stride=2,\n",
    "                               padding=1,\n",
    "                               bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    # define how to propagate \n",
    "    # through this network\n",
    "    def forward(self, inputs):\n",
    "        output = self.main(inputs)\n",
    "        return output\n",
    "\n",
    "# create the model that will evaluate \n",
    "# the generated monsters\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=d_filter_depth_in, \n",
    "                      out_channels=64, \n",
    "                      kernel_size=4, \n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, \n",
    "                      out_channels=128, \n",
    "                      kernel_size=3, \n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=128, \n",
    "                      out_channels=256, \n",
    "                      kernel_size=4, \n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, \n",
    "                      out_channels=512, \n",
    "                      kernel_size=4, \n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=512, \n",
    "                      out_channels=1, \n",
    "                      kernel_size=4, \n",
    "                      stride=1,\n",
    "                      padding=0,\n",
    "                      bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    # define forward porpagation\n",
    "    # through that model\n",
    "    def forward(self, inputs):\n",
    "        output = self.main(inputs)\n",
    "        return output.view(-1, 1).squeeze(1)\n",
    "      \n",
    "# utility functions\n",
    "\n",
    "# this iniitilaizes the parameters\n",
    "# to good rnadom values, you can\n",
    "# do more research on your own\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv2d') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        m.weight.data.normal_(1.0,0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "        \n",
    "# this converts any pytorch tensor,\n",
    "# an n-dimensional array, to a \n",
    "# variable and puts it on a gpu if\n",
    "# a one is available\n",
    "def to_variable(x):\n",
    "    '''\n",
    "    convert a tensor to a variable\n",
    "    with gradient tracking\n",
    "    '''\n",
    "    if torch.cuda.is_available():\n",
    "        x = x .cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "# we're going normalize our images\n",
    "# to make training the generator easier\n",
    "# this de-normalizes the images coming out\n",
    "# of the generator so they look intelligble\n",
    "def denorm_monsters(x):\n",
    "    renorm = (x*0.5)+0.5\n",
    "    return renorm.clamp(0,1)\n",
    "# this plots a bunch of pokemon\n",
    "# at the end of each trainign round so\n",
    "# we can get a sense for how our network\n",
    "# is doing.\n",
    "def plot_figure(fixed_noise):\n",
    "    plt.figure()\n",
    "    fixed_imgs = generator(fixed_noise)\n",
    "    result = denorm_monsters(fixed_imgs.cpu().data)\n",
    "    result = make_grid(result)\n",
    "    result = transforms.Compose([transforms.ToPILImage()])(result)\n",
    "    plt.imshow(result)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "  \n",
    "# create a generator and\n",
    "# initialize its weights\n",
    "generator = Generator()\n",
    "generator = generator.apply(weights_init)\n",
    "\n",
    "# create a discriminator and\n",
    "# initialize its weights\n",
    "discriminator = Discriminator()\n",
    "discriminator = discriminator.apply(weights_init)\n",
    "\n",
    "# create a loss object and optimizers\n",
    "loss_func = nn.BCELoss()\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.99))\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.99))\n",
    "\n",
    "# it a gpu is available, move all\n",
    "# the models and the loss function\n",
    "# to the gpu (more performant)\n",
    "if torch.cuda.is_available():\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "    loss_func.cuda()\n",
    "    \n",
    "# create a fixed_noise variable so we can evaluate results\n",
    "# consistently. if we don't do this we'll get different monsters\n",
    "# everytime we re-run and it will be hard to eavluate our generator\n",
    "fixed_noise = to_variable(torch.randn(batch_size, noise_dim, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/generator_dec317_ep_90'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m load_model \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pokemon_models, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator_dec317_ep_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m90\u001b[39m)\n\u001b[1;32m      6\u001b[0m generator_final \u001b[38;5;241m=\u001b[39m Generator()\n\u001b[0;32m----> 7\u001b[0m generator_final\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m generator_final\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# generate new monsters\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/generator_dec317_ep_90'"
     ]
    }
   ],
   "source": [
    "# create new noise to pass to the generator\n",
    "noise = to_variable(torch.randn(batch_size, noise_dim, 1, 1))\n",
    "\n",
    "# load the generator from epoch 90 of training\n",
    "load_model = os.path.join(pokemon_models, 'generator_dec317_ep_%d' % 90)\n",
    "generator_final = Generator()\n",
    "generator_final.load_state_dict(torch.load(load_model))\n",
    "generator_final.cuda()\n",
    "\n",
    "# generate new monsters\n",
    "fixed_imgs = generator_final(noise)\n",
    "result = denorm_monsters(fixed_imgs.cpu().data)\n",
    "result = make_grid(result)\n",
    "result = transforms.Compose([transforms.ToPILImage()])(result)\n",
    "\n",
    "# plot those monsters\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.imshow(result)\n",
    "plt.axis('off')\n",
    "_ = plt.show()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
